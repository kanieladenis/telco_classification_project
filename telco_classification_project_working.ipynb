{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22845f0a",
   "metadata": {},
   "source": [
    "# Telco Classificatin Project - Working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5b985",
   "metadata": {},
   "source": [
    "### Project Goals\n",
    "\n",
    "The goal of this project is to identify drivers of customer churn and and make a recommend changes that will ncrease customer retention.\n",
    "\n",
    "\n",
    "### Project Description\n",
    "\n",
    "Customer churn is a problem that is costing Telco revenue. This project attempts to identify reasons for customer churn in order to increase customer retention and reduce loss of revenue. The knowledge gained could expand beyond customer retention to improve sales by identifying what customers like and dislike. This project will anaylize the attributes of customers that churn to build a model that will predict the probablity of a customer churning given specific attributes. \n",
    "\n",
    "### Initial Questions\n",
    "\n",
    "How many customers are churning?\n",
    "\n",
    "At what month of tenure are they churning?\n",
    "\n",
    "What non-monetary drivers are associated with churned customers?\n",
    "\n",
    "What monetary drivers are associated with churned customers?\n",
    "\n",
    "Do monetary drivers outweigh non-monetary drivers?\n",
    "\n",
    "What drivers are easiest to change with least amount of impact to the customer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get Data\n",
    "- Added env.py to the repo .gitignore\n",
    "- Created an env file that contains my username, password, and host address.\n",
    "- Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef743089",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prep Data and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explore Train Data to answer the 4 questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1919779",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Provide 5-min Visuals for exploration (two with statistical test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c801e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Summarize Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee7f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f24f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Select Evaluation Metric (Report.ipynb)\n",
    "##### Evaluate Baseline (Report.ipynb)\n",
    "##### Develop 3 Models (Report.ipynb)\n",
    "#### Evaluate on Train (Report.ipynb)\n",
    "##### Evaluate on Validate (Report.ipynb)\n",
    "##### Evaluate Top Model on Test (Report.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Report (Final Notebook) \n",
    "\n",
    "#### code commenting (Report.ipynb)\n",
    "#### markdown (Report.ipynb)\n",
    "\n",
    "#### Written Conclusion Summary (Report.ipynb)\n",
    "\n",
    "#### conclusion recommendations (Report.ipynb)\n",
    "\n",
    "#### conclusion next steps (Report.ipynb)\n",
    "\n",
    "#### no errors (Report.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eaa31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Live Presentation\n",
    "\n",
    "### intro (live)\n",
    "\n",
    "### audience & setting  (live)\n",
    "\n",
    "### content (live)\n",
    "\n",
    "### Verbal Conclusion (findings, next steps, recommendations)  (live) \n",
    "\n",
    "### time (live) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78151473",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deliver Predictions\n",
    "\n",
    "### Deliver predictions (.csv) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b186d4",
   "metadata": {},
   "source": [
    "intro\n",
    "\n",
    "goals\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e21a1c",
   "metadata": {},
   "source": [
    "acquire data from ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e8127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import acquireTitanic\n",
    "\n",
    "df = acquireTitanic.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c72a41",
   "metadata": {},
   "source": [
    "Prep data by...\n",
    "\n",
    "- encode embarked\n",
    "- drop embarked and embark_town (interdependent on each other and represented in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af77e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a195780",
   "metadata": {},
   "source": [
    "**to-do**\n",
    "\n",
    "1. Class/pclass: Do pclass and class represent the same info? If so, drop class and keep pclass because it is represented as an integer.\n",
    "1. Dummy Vars: Are embarked and embark_town represent the same information? If so, get dummy variables for sex, embarked\n",
    "1. Drop columns: embarked and sex columns (now dummy vars), deck (almost 700 missing values), class (#1 above was a YES). \n",
    "1. Drop rows: where age is missing (177 rows are missing values, and age will likely be a very influential feature). \n",
    "1. Write prep function\n",
    "1. Split data\n",
    "1. Write split function\n",
    "1. Write prep_split_function\n",
    "\n",
    "*1. Class/pclass: Do pclass and class represent the same info? If so, drop class and keep pclass because it is represented as an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e442dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['class'], df['pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d93338",
   "metadata": {},
   "source": [
    "Yes! Add 'class' to the list of columns to drop. \n",
    "\n",
    "*2. Dummy Vars: Do embarked and embark_town represent the same information? If so, get dummy variables for sex, embarked*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.embarked, df.embark_town)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9df77f",
   "metadata": {},
   "source": [
    "YES! Get dummy variables for sex, embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f826aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the boolean variables for classes in the sex and embarked columns, dropping one of the categories for each \n",
    "# original column\n",
    "\n",
    "dummies_df = pd.get_dummies(df[['sex', 'embarked']], drop_first=True)\n",
    "dummies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the dummy var to the original dataframe\n",
    "df_with_dummies = pd.concat([df, dummies_df], axis=1)\n",
    "df_with_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify sex\n",
    "pd.crosstab(df_with_dummies.sex, df_with_dummies.sex_male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238a7d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify embarked\n",
    "df_with_dummies.groupby('embarked')[['embarked_Q', 'embarked_S']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d038672",
   "metadata": {},
   "source": [
    "*3. Drop columns: embarked and sex columns (now dummy vars), deck (almost 700 missing values), class (#1 above was a YES). *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7240fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns represented in dummy vars\n",
    "df_dropped_cols_with_dummies = df_with_dummies.drop(columns=['embarked', 'sex', 'deck', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479a314",
   "metadata": {},
   "source": [
    "*4. Drop rows where age is missing (177 rows are missing values, and age will likely be a very influential feature).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891d3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where age is missing\n",
    "df_cleaned = df_dropped_cols_with_dummies[df_dropped_cols_with_dummies.age.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08267383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop 2 rows where embark_town is null. \\\n",
    "df_cleaned = df_cleaned[df_cleaned.embark_town.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at our prepped data\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bdc28",
   "metadata": {},
   "source": [
    "*6. Write prep function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titanic(df):\n",
    "    '''\n",
    "    This function takes in dataframe as argument, \n",
    "    create dummy variables out of sex and embarked, and concats those to original dataframe\n",
    "    drops columns embarked, sex, deck, class\n",
    "    drops rows where age (177 rows) or embarked_town (2 rows) are null. \n",
    "    it returns the new cleaned dataframe.\n",
    "    '''\n",
    "    dummies_df = pd.get_dummies(df[['sex', 'embarked']], drop_first=True)\n",
    "    df_with_dummies = pd.concat([df, dummies_df], axis=1)\n",
    "    df_dropped_cols_with_dummies = df_with_dummies.drop(columns=['embarked', 'sex', 'deck', 'class'])\n",
    "    df_cleaned = df_dropped_cols_with_dummies[df_dropped_cols_with_dummies.age.notnull()]\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e3b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_titanic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9647b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "seed = 123\n",
    "train_and_validate, test = train_test_split(\n",
    "        df, test_size=0.2, random_state=seed, stratify=df.survived\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13337cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate = train_test_split(\n",
    "        train_and_validate,\n",
    "        test_size=0.3,\n",
    "        random_state=seed,\n",
    "        stratify=train_and_validate.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae96d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(prepped_df, seed=123):\n",
    "    train_and_validate, test = train_test_split(\n",
    "        prepped_df, test_size=0.2, random_state=seed, stratify=prepped_df.survived\n",
    "    )\n",
    "    train, validate = train_test_split(\n",
    "        train_and_validate,\n",
    "        test_size=0.3,\n",
    "        random_state=seed,\n",
    "        stratify=train_and_validate.survived,\n",
    "    )\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3774809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = train_validate_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec593d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"(Rows, Columns)\\nTrain: \", train.shape, \n",
    "      \"\\nValidate: \", validate.shape, \n",
    "      \"\\nTest: \", test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43bf0cc",
   "metadata": {},
   "source": [
    "Analyze Survival"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
